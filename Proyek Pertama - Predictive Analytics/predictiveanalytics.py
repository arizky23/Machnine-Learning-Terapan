# -*- coding: utf-8 -*-
"""PredictiveAnalytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fOtdgtgfbn8DVeFQ9OOCggxJ5F8BBBqD

# **Data Diri**

---
Nama : Ananda Rizky Nurhidayat

Alamat : Kabupaten Bekasi, Cikarang Selatan

Email : anandakiki1984@gmail.com

SIB Email : M314X0817@dicoding.org

SIB ID : M314X0817

# Introduction :
Topik dalam proyek pertama terkait Predictive Analytic ini membahas terkait Prediksi Harga Penerbangan dengan 12 atribut. Topik ini untuk memenuhi Submission pertama dalam Machine Learning Terapan

# Data Collection

Import library yang dibutuhkan. Anda dapar melakukan di awal atau di tiap kode sel.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
# %matplotlib inline

"""Kaggle API setup"""

!pip install kaggle

"""Upload API token yang berformat .json

> API token ini bisa kita dapatkan dari web kaggle yang sudah kalian loginkan. Ketika anda sudah login, lalu kalian pergi ke bagian akun anda, anda scroll kebawah dan nanti anda akan menemukan Create New API Token pada bagian API
"""

from google.colab import files
files.upload()

"""Memindahkan file kaggle.json kedalam config folder"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# gunakan ls untuk melihat apakah sudah masuk kedalam folder atau belum
!ls ~/.kaggle

"""Mempersiapkan dataset dengan mengunduhnya melalui website kaggle"""

!kaggle datasets download -d shubhambathwal/flight-price-prediction

"""Melakukan pengekstrakan terhadap dataset dengan menggunakan perintah unzip"""

!unzip flight-price-prediction.zip

"""Membaca file dataset yang telah kita download tadi"""

df = pd.read_csv('/content/Clean_Dataset.csv')
df.head()

"""Output kode di atas memberikan informasi sebagai berikut:
- Terdapat 300.153 baris (records atau jumlah pengamatan) dalam dataset tersebut.
- Terdapat 12 kolom yaitu: Unnamed: 0, airline, flight, source_city, departure_time, destination_city, class, duration, days_left, dan price.

# Data Understanding

> Deskripsi Dataset

Untuk mengecek informasi pada dataset, gunakan fungsi info() sebagai berikut.
"""

df.info()

"""Berbagai fitur dari dataset yang dibersihkan dijelaskan di bawah ini:

1. Airline / Maskapai penerbangan: Nama perusahaan penerbangan disimpan di kolom maskapai penerbangan.
2. Flight / Penerbangan: Penerbangan menyimpan informasi mengenai kode penerbangan pesawat.
3. Source City / Sumber Kota: Kota tempat penerbangan lepas landas.
4. Departure Time / Waktu Keberangkatan: Ini menyimpan informasi tentang waktu keberangkatan
5. Stops / Berhenti: Menyimpan jumlah perhentian antara kota sumber dan tujuan.
6. Arrival Time / Waktu Kedatangan: Menyimpan informasi tentang waktu kedatangan.
7. Destination City / Kota Tujuan: Kota tempat penerbangan akan mendarat.
8. Class / Kelas: Fitur kategori yang berisi informasi tentang kelas kursi; dengan dua nilai yang berbeda: Bisnis dan Ekonomi.
9. Duration / Durasi: Jumlah keseluruhan waktu yang diperlukan untuk melakukan perjalanan antar kota dalam hitungan jam.
10. Days Left / Hari Tersisa: Dihitung dengan mengurangi tanggal perjalanan berdasarkan tanggal pemesanan.
11. Price / Harga: Target variabel menyimpan informasi harga tiket.

Drop kolom yang tidak diperlukan

> Dikarenakan Unnamed: 0 tidak memiliki nilai yang dapat kita olah, dan stops yang saya rasa tidak terpakai, maka disini saya akan membuang kedua kolom tersebut dengan perintah sebagai berikut.
"""

df = df.drop(['Unnamed: 0', 'stops'], axis=1)
df.info()

"""Setelah kita drop kolom Unnamed: 0 dan stops, dapat kita lihat outputnya bahwa:

- Terdapat 7 kolom dengan tipe object, yaitu: airline, flight, source_city, departure_time, arrival_time, destination_city, dan class. ini merupakan categorical features (fitur non-numerik).
- Terdapat 1 kolom numerik dengan tipe data float64 yaitu: duration. Ini merupakan fitur numerik yang merupakan hasil pengukuran secara fisik.
- Terdapat 2 kolom numerik dengan tipe data int64, yaitu: days_left dan price. Disini kita akan menargetkan pada kolom price untuk target fitur kita.

Selanjutnya kita akan mengecek deskripsi statistik dari data tersebut dengan fungsi Describe()
"""

df.describe()

"""Fungsi describe() memberikan informasi statistik pada masing-masing kolom, antara lain:

- Count  adalah jumlah sampel pada data.
- Mean adalah nilai rata-rata.
- Std adalah standar deviasi.
- Min yaitu nilai minimum setiap kolom. 
- 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama. 
- 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- 75% adalah kuartil ketiga.
- Max adalah nilai maksimum.

Sebelum kita eksekusi, disini saya akan mengecek terlebih dahulu data yang saya dapat, apakah sudah bersih atau masih berantakan.

> Check Missing Value

Dalam proses ini kita akan mengecek nilai dari tiap kolom, apakah ada yang null(kosong) atau tidak. Disini kita gunakan fungsi isna().sum()
"""

df.isna().sum()

"""Dapat kita lihat bahwa setiap tabel tidak memiliki missing value

> Check Unique Value

Selanjutnya, dalam proses ini kita akan mengecek nilai dari tiap kolom, apakah memiliki nilai unik atau tidak. Disini kita gunakan fungsi nunique()
"""

df.nunique()

"""> Check Duplicate

kemudian dalam proses ini kita akan mengecek apakah ada yang terduplikasi dalam tiap kolom. Disini kita gunakan fungsi duplicated().sum()
"""

df.duplicated().sum()

"""Tidak terdapat duplikasi data disini

> Data Size Check

Untuk melihat ukuran data kita gunakan fungsi shape
"""

df.shape

"""Terdapat 300.153 baris (records atau jumlah pengamatan) dan 10 kolom dalam dataset tersebut.

# Univariate Analysis

Disini saya akan menghitung terlebih dahulu dari masing-masing kolom, melihat berapa banyak isi dari kolom tersebut.

> Categorical Features

- Airline
"""

df.groupby('airline')['airline'].agg('count')

"""- Flight"""

df.groupby('flight')['flight'].agg('count')

"""Karena disini flight memiliki banyak sekali nilai unique, maka akan kita lakukan drop fitur."""

df = df.drop(['flight'], axis=1)

"""- Source City"""

df.groupby('source_city')['source_city'].agg('count')

"""- Departure Time"""

df.groupby('departure_time')['departure_time'].agg('count')

"""- Arrival Time"""

df.groupby('arrival_time')['arrival_time'].agg('count')

"""- Destination City"""

df.groupby('destination_city')['destination_city'].agg('count')

"""- Class"""

df.groupby('class')['class'].agg('count')

"""Kita lihat kembali dataset tersebut dengan fungsi head() sebagai berikut."""

df.head()

"""Dan kita akan mengecek kembali informasi pada dataset tersebut dengan fungsi info() sebagai berikut."""

df.info()

"""> Separation of features

Selanjutnya, akan kita bagi fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features.
"""

numerical_features = ['duration', 'days_left', 'price']
categorical_features = ['airline', 'source_city','departure_time', 'arrival_time', 'destination_city', 'class']

"""> Numerical Features

Untuk fitur numerik, kita akan melihat histogram masing-masing fiturnya menggunakan code berikut.
"""

df.hist(bins=50, figsize=(10,10))
plt.show()

"""Grafik diatas memiliki distribusi yang banyak

# Multivariate Analysis

> Categorical Features

Pada tahap ini, kita akan mengecek rata-rata harga terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap harga.
"""

# Melihat kolerasi antara fitur kategorik dengan fitur target (harga)
cat_features = df.select_dtypes(include='object').columns.to_list()
 
for col in cat_features:
  sns.catplot(x=col, y="price", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="Set3")
  plt.title("Rata-rata 'Price' Relatif terhadap - {}".format(col))

"""Dengan mengamati rata-rata harga relatif terhadap fitur kategori di atas, kita memperoleh insight sebagai berikut:
- Pada fitur ‘airline’, rata-rata harga cenderung tak beraturan. Grade tertinggi yaitu grade Vistara memiliki harga 30000 lebih tinggi diantara grade lainnya. Sehingga, fitur airline memiliki pengaruh atau dampak yang kecil terhadap rata-rata harga.
- Pada fitur ‘source_city’, rata-rata harga cenderung mirip. Rentangnya berada antara 18000 hingga 30000. Dari sini dapat disimpulkan bahwa kota tempat penerbangan lepas landas memiliki pengaruh yang rendah terhadap harga.
- Pada fitur ‘departure time’, waktu keberangkatan sedikit berpengaruh terhadapt harga.
- Pada fitur ‘arrival time’, waktu kedatangan cenderung lebih berpengeruh terhadap harga.
- Pada fitur ‘destination city’, rata-rata harganya cenderung mirip. Rentangnya berada di antara 18000 hingga 25000.
- Pada fitur ‘class’, dapat kita lihat bahwa class yang ada pada business lebih tinggi harganya dibanding dengan economy. Ini sangat berpengaruh terhadap harga, sebab dari kedua kategori tersebut memiliki fasilitas yang berbeda.

Kesimpulan akhir, fitur kategori ini memiliki pengaruh yang signifikan terhadap harga.

> Numerical Features

Untuk mengamati hubungan antara fitur numerik, kita akan menggunakan fungsi pairplot() sebagai berikut.
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

"""> Check Correlation

Kita juga akan mengobservasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr().
"""

# Untuk mengevaluasi skor korelasinya, kita gunakan fungsi corr()
plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)
 
# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix for Numerical Features", size=20)

"""Jika kita amati, fitur ‘duration’ memiliki skor korelasi yang besar berada di 0.22 dengan fitur target ‘price’. Sementara itu, fitur ‘days_left’ memiliki korelasi yang sangat kecil yaitu -0.09. Sehingga, fitur tersebut dapat di-drop."""

df.drop(['days_left'], inplace=True, axis=1)
df.head()

"""# Check Outliers

Pada tahap ini, kita akan menangani outliers pada fitur numerik.

> Menjabarkan outliers

Disini kita menggunakan library seaborn dengan fungsi boxplot, untuk kodenya sebagai berikut.
"""

# duration
sns.boxplot(x=df['duration'])

# price
sns.boxplot(x=df['price'])

"""Jika kita perhatikan kembali, pada beberapa fitur numerik di atas terdapat outliers. Kita akan mengatasi outliers tersebut dengan menggunakan metode IQR. Menggunakan metode IQR ini tujuannya untuk mengidentifikasi outlier yang berada di luar Q1 dan Q3. Nilai apa pun yang berada di luar batas ini akan dianggap sebagai outlier.

> Mengatasi outliers menggunakan metode IQR

Hal pertama yang perlu Kita perhatikan adalah membuat batas bawah dan batas atas. Untuk membuat batas bawah, kurangi Q1 dengan 1,5 * IQR. Kemudian, untuk membuat batas atas, tambahkan 1.5 * IQR dengan Q3.

Berikut persamaannya:
- Batas bawah = Q1 - 1.5 * IQR
- Batas atas = Q3 + 1.5 * IQR

Mari kita terapkan persamaan ini ke dalam kode berikut.
"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3-Q1
df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]

# cek ukuran dataset setelah kita drop outliers
df.shape

"""# Data Preparation

> One Hot Encoding

Untuk melakukan proses encoding fitur kategori, salah satu teknik yang umum dilakukan adalah teknik one-hot-encoding. Library scikit-learn menyediakan fungsi ini untuk mendapatkan fitur baru yang sesuai sehingga dapat mewakili variabel kategori. Kita memiliki enam variabel kategori dalam dataset kita, yaitu ‘airline’, ‘source_city’, ‘departure_time’, ‘arrival_time’, ‘destination_city’, dan ‘class’.
"""

# Mari kita lakukan proses encoding ini dengan fitur get_dummies.
from sklearn.preprocessing import OneHotEncoder
df = pd.concat([df, pd.get_dummies(df['airline'], prefix='airline')],axis=1)
df = pd.concat([df, pd.get_dummies(df['source_city'], prefix='source_city')],axis=1)
df = pd.concat([df, pd.get_dummies(df['departure_time'], prefix='departure_time')],axis=1)
df = pd.concat([df, pd.get_dummies(df['arrival_time'], prefix='arrival_time')],axis=1)
df = pd.concat([df, pd.get_dummies(df['destination_city'], prefix='destination_city')],axis=1)
df = pd.concat([df, pd.get_dummies(df['class'], prefix='class')],axis=1)
df.drop(['airline','source_city','departure_time', 'arrival_time', 'destination_city', 'class'], axis=1, inplace=True)
df.head()

"""Sekarang, variabel kategori kita telah berubah menjadi variabel numerik

> Train Test Split

Membagi dataset menjadi data latih (train) dan data uji (test) merupakan hal yang harus kita lakukan sebelum membuat model. Kita perlu mempertahankan sebagian data yang ada untuk menguji seberapa baik generalisasi model terhadap data baru.

Ketahuilah bahwa setiap transformasi yang kita lakukan pada data juga merupakan bagian dari model. Karena data uji (test set) berperan sebagai data baru, kita perlu melakukan semua proses transformasi dalam data latih. Inilah alasan mengapa langkah awal adalah membagi dataset sebelum melakukan transformasi apa pun. Tujuannya adalah agar kita tidak mengotori data uji dengan informasi yang kita dapat dari data latih.
"""

# kita akan membagi dataset sebesar 70:30 dengan fungsi train_test_split dari sklearn.
from sklearn.model_selection import train_test_split

X = df.drop(["price"],axis=1)
y = df["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 123)

# untuk mengecek jumlah sampel pada masing-masing bagian, kita gunakan kode berikut
print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""> Standarisasi

Standardisasi adalah teknik transformasi yang paling umum digunakan dalam tahap persiapan pemodelan. Untuk fitur numerik, kita tidak akan melakukan transformasi dengan one-hot-encoding seperti pada fitur kategori. Kita akan menggunakan teknik StandarScaler dari library Scikitlearn.

Untuk menghindari kebocoran informasi pada data uji, kita hanya akan menerapkan fitur standarisasi pada data latih. Kemudian, pada tahap evaluasi, kita akan melakukan standarisasi pada data uji.
"""

# Mari kita terapkan StandardScaler pada data.
from sklearn.preprocessing import StandardScaler

# Kita akan menormalisasikan data pada data train
numerical_features = ['duration']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""Seperti yang telah disebutkan sebelumnya, proses standarisasi mengubah nilai rata-rata (mean) menjadi 0 dan nilai standar deviasi menjadi 1."""

# Untuk mengecek nilai mean dan standar deviasi pada setelah proses standarisasi, jalankan kode ini:
X_train[numerical_features].describe().round(4)

"""Perhatikan tabel di atas, sekarang nilai mean = 0 dan standar deviasi = 1.

# Modeling Development

Pada tahap ini kita akan membuat tiga buah model machine learning dengan algoritma berikut:

- K-Nearest Neighbor (KNN)
- Random Forest
- Boosting Algorithm
"""

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['accuracy'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)

models.loc['accuracy','knn'] = mean_squared_error(y_pred=knn.predict(X_train), y_true=y_train)

from sklearn.ensemble import RandomForestRegressor

# Buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
models.loc['accuracy', 'RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

# untuk menerapkan model pada dataset, implementasikan code berikut.
from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)
boosting.fit(X_train, y_train)
models.loc['accuracy', 'Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# Evaluasi Model

Sebelum menghitung nilai MSE dalam model, kita perlu melakukan proses scaling fitur numerik pada data uji. Sebelumnya, kita baru melakukan proses scaling pada data latih untuk menghindari kebocoran data.

Sekarang, setelah model selesai dilatih dengan 3 algoritma, yaitu KNN, Random Forest, dan Adaboost, kita perlu melakukan proses scaling terhadap data uji. Hal ini harus dilakukan agar skala antara data latih dan data uji sama dan kita bisa melakukan evaluasi.

Untuk proses scaling, implementasikan kode berikut:
"""

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""Selanjutnya, mari kita evaluasi ketiga model kita dengan metrik MSE yang telah dijelaskan di atas. Jalankan kode berikut."""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN', 'RF', 'Boosting'])

# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
  mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
  mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

"""Perhatikanlah potongan kode di atas. Saat menghitung nilai Mean Squared Error pada data train dan test, kita membaginya dengan nilai 1e3. Hal ini bertujuan agar nilai mse berada dalam skala yang tidak terlalu besar."""

# Membuat plot metrik tersebut dengan bar chart.
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari gambar di atas, terlihat bahwa, model Random Forest (RF) memberikan nilai eror yang paling kecil. Sedangkan model dengan algoritma Boosting memiliki eror yang paling besar (berdasarkan grafik, angkanya di atas 35000). Model inilah yang akan kita pilih sebagai model terbaik untuk melakukan prediksi harga penerbangan.

Untuk mengujinya, mari kita buat prediksi menggunakan beberapa harga dari data test.
"""

prediksi = X_test.iloc[5:10].copy()
pred_dict = {'y_true':y_test[5:10]}
for name, model in model_dict.items():
  pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)